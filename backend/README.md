# Trial Generalized Automation Agent - Backend

A production-oriented trial generalized automation agent that combines conversational AI with browser automation capabilities.

## Features

âœ¨ **Dual-Mode operation:**
- **Chat Mode**: Natural conversation using local LLM (LM Studio)
- **Automation Mode**: Browser automation for web tasks

ğŸ¤– **Intelligent Intent Routing**: Automatically detects whether user wants to chat or automate

ğŸŒ **Browser Automation**: Playwright-based automation with support for:
- Opening URLs and navigating pages
- Search queries
- Clicking elements
- Scrolling and text extraction
- Form filling and interactions

ğŸ“‹ **Structured Planning**: Action plans generated by LLM before execution

ğŸ”„ **Graceful Error Handling**: Automatic retries and detailed status messages

## Architecture

```
User Message
    â†“
Intent Router (identifies chat vs automation)
    â”œâ”€â”€ Chat â†’ LLM Client â†’ Natural response
    â””â”€â”€ Automation â†’ Planner â†’ Browser Controller â†’ Status updates
```

## Project Structure

```
backend/
â”œâ”€â”€ api_server.py           # FastAPI main server
â”œâ”€â”€ intent_router.py        # Intent classification logic
â”œâ”€â”€ llm_client.py          # LM Studio integration
â”œâ”€â”€ planner.py             # Action plan generation
â”œâ”€â”€ browser_controller.py   # Playwright automation
â”œâ”€â”€ executor.py            # Plan execution engine
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ schemas.py         # Pydantic models
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ logger.py          # Logging configuration
â””â”€â”€ requirements.txt
```

## Installation

### Prerequisites

- Python 3.9+
- LM Studio running locally (for chat functionality)
- Playwright browsers installed

### Setup

1. **Install dependencies:**
```bash
pip install -r requirements.txt
```

2. **Install Playwright browsers:**
```bash
playwright install chromium
```

3. **Start LM Studio:**
   - Download from https://lmstudio.ai
   - Load a model (e.g., Mistral 7B Instruct)
   - Start the local API server on http://localhost:1234

## Running the Server

```bash
python api_server.py
```

The server will start on `http://localhost:8000`

**API Documentation**: Visit http://localhost:8000/docs

## Usage Examples

### Chat Request

```bash
curl -X POST http://localhost:8000/agent/message \
  -H "Content-Type: application/json" \
  -d '{"message": "What is machine learning?"}'
```

Response:
```json
{
  "response": "Machine learning is a field of artificial intelligence...",
  "intent": "chat",
  "session_id": "..."
}
```

### Automation Request

```bash
curl -X POST http://localhost:8000/agent/message \
  -H "Content-Type: application/json" \
  -d '{"message": "Search for best free Python course"}'
```

Response:
```json
{
  "response": "I've executed your automation request. Here's what happened:\nâœ“ All 4 steps completed successfully!",
  "intent": "automation",
  "plan": {
    "steps": [
      {"action": "open_url", "value": "https://google.com", ...},
      {"action": "search", "value": "best free Python course", ...},
      ...
    ]
  },
  "session_id": "..."
}
```

### Streaming Response

```bash
curl -X POST http://localhost:8000/agent/message/stream \
  -H "Content-Type: application/json" \
  -d '{"message": "Search for Python tutorials"}' \
  -N  # No buffering for real-time streaming
```

## API Endpoints

### Main Endpoints

- **POST /agent/message** - Send message and get response
- **POST /agent/message/stream** - Streaming variant for real-time updates
- **GET /health** - Health check
- **GET /sessions/{session_id}** - Get session info

### Browser Control (Manual)

- **POST /browser/start** - Manually start browser
- **POST /browser/stop** - Manually stop browser

## Configuration

Edit in `api_server.py` to change:

```python
llm_client = LLMClient(
    base_url="http://localhost:1234/v1",  # LM Studio endpoint
    model="mistral-7b-instruct"  # Model name
)

browser_controller = BrowserController(
    headless=True,  # Run browser in headless mode
    timeout_ms=30000  # Timeout for operations
)
```

## Supported Browser Actions

| Action | Description | Parameters |
|--------|-------------|------------|
| `open_url` | Open a website | `value`: URL |
| `search` | Search query | `value`: search term |
| `click` | Click element | `selector`: CSS selector |
| `click_first_result` | Click first search result | None |
| `scroll` | Scroll page | `value`: up/down, `amount`: times |
| `extract_text` | Get page text | `selector`: optional element |
| `fill_input` | Fill input field | `selector`: CSS selector, `value`: input |
| `wait` | Wait duration | `duration_ms`: milliseconds |
| `navigate_back` | Go back | None |

## Intent Classification

The system classifies requests as **automation** if they contain:

- Action verbs: open, search, find, click, scroll, navigate
- URL patterns: http, www, .com domains
- Command-like phrasing

Otherwise classified as **chat**.

## Error Handling

- Automatic retry on failure (configurable)
- Graceful degradation with status messages
- Detailed logging to `logs/agent.log`
- HTTP error responses with helpful details

## Logging

Logs are written to:
- **Console**: INFO level
- **File** (`logs/agent.log`): DEBUG level

## Production Considerations

âœ… **Already implemented:**
- Async/await for non-blocking I/O
- Proper error handling and retries
- Structured logging
- CORS support for frontend integration
- Session tracking
- Health checks
- Modular architecture

ğŸ“‹ **For production deployment:**
1. Use environment variables for configuration
2. Implement request authentication/authorization
3. Add rate limiting
4. Monitor LLM and browser health
5. Implement session persistence
6. Add request validation
7. Use production ASGI server (Gunicorn + Uvicorn)

## Example: Full Workflow

**User**: "Open Google and search for Python tutorials"

**System Flow**:
1. âœ… Intent Router â†’ Detects: AUTOMATION
2. âœ… Planner â†’ Generates steps:
   - open_url: https://google.com
   - search: "Python tutorials"
   - click_first_result
3. âœ… Browser Controller â†’ Executes each step
4. âœ… Executor â†’ Sends status updates:
   - "Opening Googleâ€¦"
   - "Searching for Python tutorialsâ€¦"
   - "Opening the first resultâ€¦"
5. âœ… Returns final message: "âœ“ All 3 steps completed successfully!"

## Troubleshooting

### LLM not responding
- Check: Is LM Studio running on http://localhost:1234?
- Check: Is a model loaded in LM Studio?
- Check: Is the API server enabled?

### Browser automation fails
- Ensure: `playwright install chromium` was run
- Check: Network connectivity
- Check: Target website blocking automated access

### Timeout errors
- Increase `timeout_ms` in BrowserController
- Check: Internet connection speed
- Check: Target website responsiveness

## Future Enhancements

- [ ] Web UI frontend (Lovable integration)
- [ ] Multi-browser support (Firefox, Safari)
- [ ] Screenshot/video recording
- [ ] Advanced element selection (ML-based)
- [ ] Workflow persistence and replay
- [ ] Distributed execution
- [ ] Custom action plugins

## License

MIT
